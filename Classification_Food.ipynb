{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "### Prediction for FOOD related business\n",
    "To have clearity in understanding which feature columns contributes in our prediction we can broadly categorize the business into different Categories like Food, Entertaiment, Medical, Services, Shooping, Education etc. For predicting the popularity of the Yelp business we decide to choose Food related business and feature columns.\n",
    "\n",
    "Sub categories under Food category are 'Wine Bars','Vietnamese','vegetarian','vegan','Turkish','Thai','Tex-Mex','Tea Rooms','Tapas/Small Plates','Tapas Bars','Taiwanese','Szechuan','Sushi Bars','Steakhouses','Soup','Soul Food','Seafood','Sandwiches','Salad','Russian','Restaurants','restaurant' etc.\n",
    "\n",
    "The feature columns related to food are review_count,stars,Take-out,GoodFor_lunch,GoodFor_dinner,GoodFor_breakfast,Noise_Level, Takes_Reservations,Delivery,Parking_lot,WheelchairAccessible,Alcohol,WaiterService,Wi-Fi.\n",
    "\n",
    "California State University, Los Angeles\n",
    "\n",
    "Author: Ruchi Singh\n",
    "\n",
    "Instructor: Jongwook Woo\n",
    "\n",
    "Date: 05/20/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data\n",
    "download the \"Business-Food.csv\" file and upload in Databricks. Data-> default-> Create Table. Rename the table as \"Food2\" and check for all the columns datatype.\n",
    "\n",
    "This is the data to be used for training the machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logestic regression\n",
    "The Logestic Regression classification model is used to predict the stars (popularity) for the business.The assumtion made here is that the business is unpopular if the Star is less than 3 and the business is popular if the Stars are more than 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data\n",
    "First, import the libraries you will need and prepare the training and test data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession \n",
    "spark = SparkSession.builder.master(\"local\").appName(\"classification\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Food table\n",
    "Food table created is now loaded in Spark using SQL query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('Business-Food.csv', inferSchema=True , header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.registerTempTable(\"food2\")\n",
    "csv = sqlContext.sql(\"Select * from food2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = csv.select(\"review_count\",\"Take-out\", \"GoodFor_lunch\", \"GoodFor_dinner\", \"GoodFor_breakfast\"\n",
    "                  ,\"Noise_Level\", \"Takes_Reservations\",\"Delivery\",\"Parking_lot\", \"WheelchairAccessible\"\n",
    "                  ,\"Alcohol\", \"WaiterService\",\"Wi-Fi\",\"stars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-------------+--------------+-----------------+-----------+------------------+--------+-----------+--------------------+--------+-------------+-----+-----+\n",
      "|review_count|Take-out|GoodFor_lunch|GoodFor_dinner|GoodFor_breakfast|Noise_Level|Takes_Reservations|Delivery|Parking_lot|WheelchairAccessible| Alcohol|WaiterService|Wi-Fi|stars|\n",
      "+------------+--------+-------------+--------------+-----------------+-----------+------------------+--------+-----------+--------------------+--------+-------------+-----+-----+\n",
      "|           4|    TRUE|        FALSE|         FALSE|            FALSE|    average|             FALSE|   FALSE|      FALSE|                 N/A|    none|        FALSE|  N/A|    1|\n",
      "|          20|    TRUE|         TRUE|         FALSE|            FALSE|    average|             FALSE|   FALSE|      FALSE|                 N/A|full_bar|         TRUE|   no|    1|\n",
      "|          21|    TRUE|        FALSE|          TRUE|            FALSE|       loud|             FALSE|   FALSE|       TRUE|                 N/A|full_bar|         TRUE| free|    1|\n",
      "|           8|    TRUE|        FALSE|         FALSE|            FALSE|        N/A|             FALSE|   FALSE|      FALSE|                TRUE|    none|         TRUE|  N/A|    1|\n",
      "|           4|     N/A|          N/A|           N/A|              N/A|        N/A|               N/A|     N/A|       TRUE|                TRUE|     N/A|          N/A|  N/A|    1|\n",
      "+------------+--------+-------------+--------------+-----------------+-----------+------------------+--------+-----------+--------------------+--------+-------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Indexer\n",
    "StringIndexer encodes a string column of labels to a column of label indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexStringColumns(df, cols):\n",
    "    #variable newdf will be updated several times\n",
    "    newdata = df\n",
    "    for c in cols:\n",
    "        si = StringIndexer(inputCol=c, outputCol=c+\"-x\")\n",
    "        sm = si.fit(newdata)\n",
    "        newdata = sm.transform(newdata).drop(c)\n",
    "        newdata = newdata.withColumnRenamed(c+\"-x\", c)\n",
    "    return newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnumeric = indexStringColumns(data, [\"Take-out\",\"GoodFor_lunch\", \"GoodFor_dinner\", \"GoodFor_breakfast\"\n",
    "                                      ,\"Noise_Level\", \"Takes_Reservations\",\"Delivery\",\"Parking_lot\",\n",
    "                                      \"WheelchairAccessible\",\"Alcohol\", \"WaiterService\",\"Wi-Fi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+--------+-------------+--------------+-----------------+-----------+------------------+--------+-----------+--------------------+-------+-------------+-----+\n",
      "|review_count|stars|Take-out|GoodFor_lunch|GoodFor_dinner|GoodFor_breakfast|Noise_Level|Takes_Reservations|Delivery|Parking_lot|WheelchairAccessible|Alcohol|WaiterService|Wi-Fi|\n",
      "+------------+-----+--------+-------------+--------------+-----------------+-----------+------------------+--------+-----------+--------------------+-------+-------------+-----+\n",
      "|           4|    1|     0.0|          0.0|           0.0|              0.0|        0.0|               0.0|     0.0|        0.0|                 0.0|    1.0|          2.0|  0.0|\n",
      "|          20|    1|     0.0|          2.0|           0.0|              0.0|        0.0|               0.0|     0.0|        0.0|                 0.0|    2.0|          0.0|  1.0|\n",
      "|          21|    1|     0.0|          0.0|           2.0|              0.0|        3.0|               0.0|     0.0|        1.0|                 0.0|    2.0|          0.0|  2.0|\n",
      "|           8|    1|     0.0|          0.0|           0.0|              0.0|        1.0|               0.0|     0.0|        0.0|                 1.0|    1.0|          0.0|  0.0|\n",
      "|           4|    1|     1.0|          1.0|           1.0|              1.0|        1.0|               1.0|     1.0|        1.0|                 1.0|    0.0|          1.0|  0.0|\n",
      "|           7|    1|     0.0|          0.0|           0.0|              0.0|        0.0|               0.0|     0.0|        1.0|                 1.0|    2.0|          0.0|  2.0|\n",
      "|          58|    1|     0.0|          0.0|           0.0|              2.0|        0.0|               0.0|     0.0|        1.0|                 2.0|    1.0|          0.0|  1.0|\n",
      "|           6|    1|     0.0|          0.0|           0.0|              0.0|        0.0|               0.0|     0.0|        0.0|                 0.0|    1.0|          0.0|  0.0|\n",
      "|           7|    1|     0.0|          0.0|           2.0|              0.0|        0.0|               0.0|     0.0|        0.0|                 0.0|    2.0|          0.0|  0.0|\n",
      "|           5|    1|     0.0|          1.0|           1.0|              1.0|        0.0|               0.0|     0.0|        0.0|                 1.0|    1.0|          2.0|  1.0|\n",
      "|           9|    0|     0.0|          1.0|           1.0|              1.0|        2.0|               1.0|     2.0|        0.0|                 0.0|    1.0|          2.0|  0.0|\n",
      "|           9|    1|     0.0|          0.0|           0.0|              0.0|        0.0|               0.0|     0.0|        0.0|                 0.0|    1.0|          0.0|  1.0|\n",
      "|          64|    1|     0.0|          0.0|           2.0|              0.0|        0.0|               2.0|     0.0|        1.0|                 1.0|    2.0|          0.0|  1.0|\n",
      "|           3|    0|     0.0|          1.0|           1.0|              1.0|        2.0|               0.0|     0.0|        2.0|                 2.0|    1.0|          2.0|  1.0|\n",
      "|           3|    1|     0.0|          1.0|           1.0|              1.0|        0.0|               1.0|     2.0|        2.0|                 0.0|    0.0|          0.0|  0.0|\n",
      "|          20|    1|     1.0|          1.0|           1.0|              1.0|        1.0|               1.0|     1.0|        0.0|                 1.0|    0.0|          1.0|  2.0|\n",
      "|           3|    0|     1.0|          1.0|           1.0|              1.0|        1.0|               1.0|     1.0|        2.0|                 0.0|    0.0|          1.0|  0.0|\n",
      "|          48|    0|     0.0|          0.0|           0.0|              0.0|        0.0|               0.0|     0.0|        1.0|                 1.0|    1.0|          0.0|  1.0|\n",
      "|          30|    1|     2.0|          0.0|           0.0|              0.0|        4.0|               2.0|     0.0|        1.0|                 1.0|    2.0|          0.0|  1.0|\n",
      "|          26|    1|     0.0|          2.0|           0.0|              0.0|        3.0|               0.0|     0.0|        1.0|                 0.0|    2.0|          0.0|  0.0|\n",
      "|           5|    0|     0.0|          0.0|           0.0|              0.0|        2.0|               0.0|     0.0|        0.0|                 1.0|    1.0|          2.0|  2.0|\n",
      "|           4|    0|     1.0|          1.0|           1.0|              1.0|        1.0|               1.0|     1.0|        2.0|                 0.0|    0.0|          1.0|  0.0|\n",
      "|         124|    1|     0.0|          0.0|           2.0|              0.0|        0.0|               2.0|     0.0|        1.0|                 1.0|    2.0|          0.0|  1.0|\n",
      "|          31|    1|     1.0|          1.0|           1.0|              1.0|        1.0|               1.0|     1.0|        1.0|                 1.0|    0.0|          1.0|  0.0|\n",
      "|          74|    0|     0.0|          0.0|           2.0|              0.0|        3.0|               2.0|     0.0|        1.0|                 1.0|    2.0|          0.0|  2.0|\n",
      "+------------+-----+--------+-------------+--------------+-----------------+-----------+------------------+--------+-----------+--------------------+-------+-------------+-----+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfnumeric.show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "One-hot encoding maps a column of label indices to a column of binary vectors, with at most a single one-value. This encoding allows algorithms which expect continuous features, in classification model, to use categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncodeColumns(df, cols):\n",
    "    from pyspark.ml.feature import OneHotEncoder\n",
    "    newdf = df\n",
    "    for c in cols:\n",
    "        onehotenc = OneHotEncoder(inputCol=c, outputCol=c+\"-onehot\", dropLast=False)\n",
    "        onehotenc = onehotenc.fit(newdf)\n",
    "        newdf = onehotenc.transform(newdf).drop(c)\n",
    "        newdf = newdf.withColumnRenamed(c+\"-onehot\", c)\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhot = oneHotEncodeColumns(dfnumeric, [\"Take-out\",\"GoodFor_lunch\", \"GoodFor_dinner\", \"GoodFor_breakfast\"\n",
    "                                        ,\"Noise_Level\", \"Takes_Reservations\",\"Delivery\",\"Parking_lot\"\n",
    "                                        , \"WheelchairAccessible\",\"Alcohol\", \"WaiterService\",\"Wi-Fi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-------------+-------------+--------------+-----------------+-------------+------------------+-------------+-------------+--------------------+-------------+-------------+-------------+\n",
      "|review_count|stars|     Take-out|GoodFor_lunch|GoodFor_dinner|GoodFor_breakfast|  Noise_Level|Takes_Reservations|     Delivery|  Parking_lot|WheelchairAccessible|      Alcohol|WaiterService|        Wi-Fi|\n",
      "+------------+-----+-------------+-------------+--------------+-----------------+-------------+------------------+-------------+-------------+--------------------+-------------+-------------+-------------+\n",
      "|           4|    1|(3,[0],[1.0])|(3,[0],[1.0])| (3,[0],[1.0])|    (3,[0],[1.0])|(5,[0],[1.0])|     (3,[0],[1.0])|(3,[0],[1.0])|(3,[0],[1.0])|       (3,[0],[1.0])|(4,[1],[1.0])|(3,[2],[1.0])|(4,[0],[1.0])|\n",
      "|          20|    1|(3,[0],[1.0])|(3,[2],[1.0])| (3,[0],[1.0])|    (3,[0],[1.0])|(5,[0],[1.0])|     (3,[0],[1.0])|(3,[0],[1.0])|(3,[0],[1.0])|       (3,[0],[1.0])|(4,[2],[1.0])|(3,[0],[1.0])|(4,[1],[1.0])|\n",
      "|          21|    1|(3,[0],[1.0])|(3,[0],[1.0])| (3,[2],[1.0])|    (3,[0],[1.0])|(5,[3],[1.0])|     (3,[0],[1.0])|(3,[0],[1.0])|(3,[1],[1.0])|       (3,[0],[1.0])|(4,[2],[1.0])|(3,[0],[1.0])|(4,[2],[1.0])|\n",
      "|           8|    1|(3,[0],[1.0])|(3,[0],[1.0])| (3,[0],[1.0])|    (3,[0],[1.0])|(5,[1],[1.0])|     (3,[0],[1.0])|(3,[0],[1.0])|(3,[0],[1.0])|       (3,[1],[1.0])|(4,[1],[1.0])|(3,[0],[1.0])|(4,[0],[1.0])|\n",
      "|           4|    1|(3,[1],[1.0])|(3,[1],[1.0])| (3,[1],[1.0])|    (3,[1],[1.0])|(5,[1],[1.0])|     (3,[1],[1.0])|(3,[1],[1.0])|(3,[1],[1.0])|       (3,[1],[1.0])|(4,[0],[1.0])|(3,[1],[1.0])|(4,[0],[1.0])|\n",
      "|           7|    1|(3,[0],[1.0])|(3,[0],[1.0])| (3,[0],[1.0])|    (3,[0],[1.0])|(5,[0],[1.0])|     (3,[0],[1.0])|(3,[0],[1.0])|(3,[1],[1.0])|       (3,[1],[1.0])|(4,[2],[1.0])|(3,[0],[1.0])|(4,[2],[1.0])|\n",
      "|          58|    1|(3,[0],[1.0])|(3,[0],[1.0])| (3,[0],[1.0])|    (3,[2],[1.0])|(5,[0],[1.0])|     (3,[0],[1.0])|(3,[0],[1.0])|(3,[1],[1.0])|       (3,[2],[1.0])|(4,[1],[1.0])|(3,[0],[1.0])|(4,[1],[1.0])|\n",
      "|           6|    1|(3,[0],[1.0])|(3,[0],[1.0])| (3,[0],[1.0])|    (3,[0],[1.0])|(5,[0],[1.0])|     (3,[0],[1.0])|(3,[0],[1.0])|(3,[0],[1.0])|       (3,[0],[1.0])|(4,[1],[1.0])|(3,[0],[1.0])|(4,[0],[1.0])|\n",
      "|           7|    1|(3,[0],[1.0])|(3,[0],[1.0])| (3,[2],[1.0])|    (3,[0],[1.0])|(5,[0],[1.0])|     (3,[0],[1.0])|(3,[0],[1.0])|(3,[0],[1.0])|       (3,[0],[1.0])|(4,[2],[1.0])|(3,[0],[1.0])|(4,[0],[1.0])|\n",
      "|           5|    1|(3,[0],[1.0])|(3,[1],[1.0])| (3,[1],[1.0])|    (3,[1],[1.0])|(5,[0],[1.0])|     (3,[0],[1.0])|(3,[0],[1.0])|(3,[0],[1.0])|       (3,[1],[1.0])|(4,[1],[1.0])|(3,[2],[1.0])|(4,[1],[1.0])|\n",
      "|           9|    0|(3,[0],[1.0])|(3,[1],[1.0])| (3,[1],[1.0])|    (3,[1],[1.0])|(5,[2],[1.0])|     (3,[1],[1.0])|(3,[2],[1.0])|(3,[0],[1.0])|       (3,[0],[1.0])|(4,[1],[1.0])|(3,[2],[1.0])|(4,[0],[1.0])|\n",
      "|           9|    1|(3,[0],[1.0])|(3,[0],[1.0])| (3,[0],[1.0])|    (3,[0],[1.0])|(5,[0],[1.0])|     (3,[0],[1.0])|(3,[0],[1.0])|(3,[0],[1.0])|       (3,[0],[1.0])|(4,[1],[1.0])|(3,[0],[1.0])|(4,[1],[1.0])|\n",
      "|          64|    1|(3,[0],[1.0])|(3,[0],[1.0])| (3,[2],[1.0])|    (3,[0],[1.0])|(5,[0],[1.0])|     (3,[2],[1.0])|(3,[0],[1.0])|(3,[1],[1.0])|       (3,[1],[1.0])|(4,[2],[1.0])|(3,[0],[1.0])|(4,[1],[1.0])|\n",
      "|           3|    0|(3,[0],[1.0])|(3,[1],[1.0])| (3,[1],[1.0])|    (3,[1],[1.0])|(5,[2],[1.0])|     (3,[0],[1.0])|(3,[0],[1.0])|(3,[2],[1.0])|       (3,[2],[1.0])|(4,[1],[1.0])|(3,[2],[1.0])|(4,[1],[1.0])|\n",
      "|           3|    1|(3,[0],[1.0])|(3,[1],[1.0])| (3,[1],[1.0])|    (3,[1],[1.0])|(5,[0],[1.0])|     (3,[1],[1.0])|(3,[2],[1.0])|(3,[2],[1.0])|       (3,[0],[1.0])|(4,[0],[1.0])|(3,[0],[1.0])|(4,[0],[1.0])|\n",
      "|          20|    1|(3,[1],[1.0])|(3,[1],[1.0])| (3,[1],[1.0])|    (3,[1],[1.0])|(5,[1],[1.0])|     (3,[1],[1.0])|(3,[1],[1.0])|(3,[0],[1.0])|       (3,[1],[1.0])|(4,[0],[1.0])|(3,[1],[1.0])|(4,[2],[1.0])|\n",
      "|           3|    0|(3,[1],[1.0])|(3,[1],[1.0])| (3,[1],[1.0])|    (3,[1],[1.0])|(5,[1],[1.0])|     (3,[1],[1.0])|(3,[1],[1.0])|(3,[2],[1.0])|       (3,[0],[1.0])|(4,[0],[1.0])|(3,[1],[1.0])|(4,[0],[1.0])|\n",
      "|          48|    0|(3,[0],[1.0])|(3,[0],[1.0])| (3,[0],[1.0])|    (3,[0],[1.0])|(5,[0],[1.0])|     (3,[0],[1.0])|(3,[0],[1.0])|(3,[1],[1.0])|       (3,[1],[1.0])|(4,[1],[1.0])|(3,[0],[1.0])|(4,[1],[1.0])|\n",
      "|          30|    1|(3,[2],[1.0])|(3,[0],[1.0])| (3,[0],[1.0])|    (3,[0],[1.0])|(5,[4],[1.0])|     (3,[2],[1.0])|(3,[0],[1.0])|(3,[1],[1.0])|       (3,[1],[1.0])|(4,[2],[1.0])|(3,[0],[1.0])|(4,[1],[1.0])|\n",
      "|          26|    1|(3,[0],[1.0])|(3,[2],[1.0])| (3,[0],[1.0])|    (3,[0],[1.0])|(5,[3],[1.0])|     (3,[0],[1.0])|(3,[0],[1.0])|(3,[1],[1.0])|       (3,[0],[1.0])|(4,[2],[1.0])|(3,[0],[1.0])|(4,[0],[1.0])|\n",
      "|           5|    0|(3,[0],[1.0])|(3,[0],[1.0])| (3,[0],[1.0])|    (3,[0],[1.0])|(5,[2],[1.0])|     (3,[0],[1.0])|(3,[0],[1.0])|(3,[0],[1.0])|       (3,[1],[1.0])|(4,[1],[1.0])|(3,[2],[1.0])|(4,[2],[1.0])|\n",
      "|           4|    0|(3,[1],[1.0])|(3,[1],[1.0])| (3,[1],[1.0])|    (3,[1],[1.0])|(5,[1],[1.0])|     (3,[1],[1.0])|(3,[1],[1.0])|(3,[2],[1.0])|       (3,[0],[1.0])|(4,[0],[1.0])|(3,[1],[1.0])|(4,[0],[1.0])|\n",
      "|         124|    1|(3,[0],[1.0])|(3,[0],[1.0])| (3,[2],[1.0])|    (3,[0],[1.0])|(5,[0],[1.0])|     (3,[2],[1.0])|(3,[0],[1.0])|(3,[1],[1.0])|       (3,[1],[1.0])|(4,[2],[1.0])|(3,[0],[1.0])|(4,[1],[1.0])|\n",
      "|          31|    1|(3,[1],[1.0])|(3,[1],[1.0])| (3,[1],[1.0])|    (3,[1],[1.0])|(5,[1],[1.0])|     (3,[1],[1.0])|(3,[1],[1.0])|(3,[1],[1.0])|       (3,[1],[1.0])|(4,[0],[1.0])|(3,[1],[1.0])|(4,[0],[1.0])|\n",
      "|          74|    0|(3,[0],[1.0])|(3,[0],[1.0])| (3,[2],[1.0])|    (3,[0],[1.0])|(5,[3],[1.0])|     (3,[2],[1.0])|(3,[0],[1.0])|(3,[1],[1.0])|       (3,[1],[1.0])|(4,[2],[1.0])|(3,[0],[1.0])|(4,[2],[1.0])|\n",
      "+------------+-----+-------------+-------------+--------------+-----------------+-------------+------------------+-------------+-------------+--------------------+-------------+-------------+-------------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfhot.show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Assembler\n",
    "VectorAssembler is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = VectorAssembler(outputCol=\"features\", inputCols=list(set(dfhot.columns)-set(['stars'])))\n",
    "lpoints = va.transform(dfhot).select(\"features\", \"stars\").withColumnRenamed(\"stars\",\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split\n",
    "Split the data into training and test data in the ratio 80:20 using a random split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = lpoints.randomSplit([0.8, 0.2])\n",
    "adulttrain = splits[0].cache()\n",
    "adultvalid = splits[1].cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Pipeline\n",
    "Now define a pipeline that creates a feature vector and trains a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(regParam=0.01, maxIter=1000, fitIntercept=True)\n",
    "lrmodel = lr.fit(adulttrain)\n",
    "lrmodel = lr.setParams(regParam=0.01, maxIter=500, fitIntercept=True).fit(adulttrain)\n",
    "lrmodel.intercept\n",
    "validpredicts = lrmodel.transform(adultvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(41,[0,3,6,9,10,1...|    0|[-1.0590798658517...|[0.25748533279105...|       1.0|\n",
      "|(41,[0,3,6,9,10,1...|    1|[-1.0590798658517...|[0.25748533279105...|       1.0|\n",
      "|(41,[0,3,6,9,10,1...|    1|[-1.0836492318831...|[0.2528160548031,...|       1.0|\n",
      "|(41,[0,3,6,9,10,1...|    1|[-0.7249206686152...|[0.32631033987436...|       1.0|\n",
      "|(41,[0,3,6,9,10,1...|    1|[-0.0956151753622...|[0.47611440075399...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validpredicts.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "Using a BinaryClassificationEvaluator the classification model used on the data is evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9256845639198134"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "bceval = BinaryClassificationEvaluator()\n",
    "bceval.evaluate(validpredicts)\n",
    "bceval.getMetricName()\n",
    "bceval.setMetricName(\"areaUnderPR\")\n",
    "bceval.evaluate(validpredicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: int, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(validpredicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "It is is to ensure that every example from the original dataset has the same chance of appearing in the training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7094784502275469"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "cv = CrossValidator().setEstimator(lr).setEvaluator(bceval).setNumFolds(2)\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.maxIter, \n",
    "                                       [1000]).addGrid(lr.regParam, \n",
    "                                                       [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]).build()\n",
    "cv.setEstimatorParamMaps(paramGrid)\n",
    "cvmodel = cv.fit(adulttrain)\n",
    "BinaryClassificationEvaluator().evaluate(cvmodel.bestModel.transform(adultvalid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Parameters\n",
    "You can tune parameters to find the best model for your data. A simple way to do this is to use **TrainValidationSplit** to evaluate each combination of parameters defined in a **ParameterGrid** against a subset of the training data in order to find the best performing parameters.\n",
    "#### Regularization \n",
    "It is a way of avoiding Imbalances in the way that the data is trained against the training data so that the model ends up being over fit to the training data. In other words It works really well with the training data but it doesn't generalize well with other data. That we can use a **regularization parameter** to vary the way that the model balances that way.\n",
    "#### Training ratio of 0.8\n",
    "It is going to use 80% of the the data that it's got in its training set to train the model and then the remaining 20% is going to use to validate the trained model.\n",
    "\n",
    "In **ParamGridBuilder**, all possible combinations are generated from regParam, maxIter, threshold. So it is going to try each combination of the parameters with 80% of the the data to train the model and 20% to to validate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.3, 0.1, 0.01]).addGrid(lr.maxIter,\n",
    "                                                                              [10, 5]).addGrid(lr.threshold, \n",
    "                                                                                        [0.35, 0.30]).build()\n",
    "tvs = TrainValidationSplit(estimator=lr, evaluator=RegressionEvaluator(), estimatorParamMaps=paramGrid, \n",
    "                           trainRatio=0.8)\n",
    "model = tvs.fit(adulttrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "Now you're ready to apply the model to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+-----+\n",
      "|            features|prediction|         probability|label|\n",
      "+--------------------+----------+--------------------+-----+\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.25938459523370...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.25938459523370...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.25516207088584...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.34044522478200...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.47351113031675...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.46983994129986...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.24072712167424...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.21104595990405...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.19627875559802...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.27189534348392...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.26754272839388...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.17189082017934...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.16484135361452...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.20865388585205...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.19855877486662...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.21435344391143...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.26271132158538...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.26271132158538...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.26057679919819...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.25076524408953...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.24323063736944...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.34432823970323...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.22918696936782...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.22338379530579...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.24730527549655...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.24730527549655...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.24593667301003...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.24593667301003...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.24525428859672...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.24457318345534...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.24253755368178...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.24186157554166...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.24118688152499...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.23850096452731...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.23716573337254...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.23517256378893...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.23122113382889...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.22861276186300...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.19660051958541...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.17080643375558...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.32787511597053...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.21641966544913...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.21393180225367...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.21393180225367...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.21331309897220...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.21269570085784...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.21207960795918...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.20780350405505...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.17165684370618...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.33128773642770...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.32317980077003...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.46677623617040...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.22671385586654...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.21344155151323...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.19655846943439...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.19424232434743...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.18910689568511...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.30342882095319...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.28884495780687...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.28432696386467...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.28283046633795...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.20137242660461...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.27532287656413...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.26443818203169...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.04350368733377...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.06939318747987...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.15802695403582...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.24025057791716...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.17129763745490...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.16921646148053...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.09957827622181...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.16485662031119...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.25024710726198...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.34039001025306...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.22226808538929...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.34636344742763...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.24135590934175...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.24000973257415...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.24000973257415...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.23733282451028...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.23401571600267...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.19849842036504...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.19863491710635...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.19055462001349...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.18660973021062...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.32257645890443...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.21963899934159...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.46334092144593...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.46242523944231...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.44417288365805...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.22174928540023...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.21858755698231...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.18057519525714...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.15442744217894...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.13485935145046...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.13187961783648...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.29268594049093...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.30753166501648...|    1|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.24189851639252...|    0|\n",
      "|(41,[0,3,6,9,10,1...|       1.0|[0.22349332778523...|    1|\n",
      "+--------------------+----------+--------------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(adultvalid)\n",
    "# LogisticRegression\n",
    "predicted = prediction.select(\"features\", \"prediction\", \"probability\", \"label\")\n",
    "\n",
    "predicted.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Confusion Matrix Metrics: Only for Classification Logistic Regression not for Linear Regression\n",
    "Classifiers are typically evaluated by creating a confusion matrix, which indicates the number of:\n",
    "\n",
    "1. True Positives\n",
    "2. True Negatives\n",
    "3. False Positives\n",
    "4. False Negatives\n",
    "\n",
    "From these core measures, other evaluation metrics such as precision and recall can be calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "Precision (0.8464591933947285), Recall (1.0): Precision becomes a little bit lower but the precision becomes much higher than previous no tuning example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|   metric|             value|\n",
      "+---------+------------------+\n",
      "|       TP|            5331.0|\n",
      "|       FP|             967.0|\n",
      "|       TN|               2.0|\n",
      "|       FN|               0.0|\n",
      "|Precision|0.8464591933947285|\n",
      "|   Recall|               1.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp = float(predicted.filter(\"prediction == 1.0 AND label == 1\").count())\n",
    "fp = float(predicted.filter(\"prediction == 1.0 AND label == 0\").count())\n",
    "tn = float(predicted.filter(\"prediction == 0.0 AND label == 0\").count())\n",
    "fn = float(predicted.filter(\"prediction == 0.0 AND label == 1\").count())\n",
    "metrics = spark.createDataFrame([\n",
    " (\"TP\", tp),\n",
    " (\"FP\", fp),\n",
    " (\"TN\", tn),\n",
    " (\"FN\", fn),\n",
    " (\"Precision\", tp / (tp + fp)),\n",
    " (\"Recall\", tp / (tp + fn))],[\"metric\", \"value\"])\n",
    "metrics.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the Area Under ROC: Only for Classification Logistic Regression \n",
    "Another way to assess the performance of a classification model is to measure the area under a ROC curve for the model. the spark.ml library includes a **BinaryClassificationEvaluator** class that you can use to compute this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[metric: string, value: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUR =  0.5050194173573229\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "aur = evaluator.evaluate(validpredicts)\n",
    "print (\"AUR = \", aur)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
